Selfdriving is a big word. At the moment the vehicle is capable of driving on roads with clear lines. This is all possible because of behaviour cloning. The basic principle of this is that we show something to a computer and they try to understand why we do it that way and then try it themself. 
I learned my car to drive itself by giving it the camera/motors inputs while controling the vehicle with the app. It tries to understand why I drive the way I do. While it trains it tries to predict how I will drive. It then compares its prediction with the outcome. Afer a while it should understand that its needs to drive between the two lines. 
It's quite logically that how more it trains how better it becomes. To improve and speed the process up you could ad more inputs, more cameras, ultrasonic sensors,... Another way is to filter the camera input to make it simpler for the AI to learn. For example filter the images so the lines are white and all the rest black.

To make it safer it is able to detect stopsigns. Be sure to download the stop_data.xml file along with the python script. I also created a model to recognize 63 different trafficsigns with my image classification software. You can find this software in the image classifiction repository along with software to implement it.
